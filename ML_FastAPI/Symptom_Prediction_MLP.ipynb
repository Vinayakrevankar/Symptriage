{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9c2fca6",
      "metadata": {
        "id": "b9c2fca6"
      },
      "source": [
        "# Symptom Prediction using MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b68b7aa3",
      "metadata": {
        "id": "b68b7aa3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"itachi9604/disease-symptom-description-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix,classification_report,confusion_matrix,precision_score,roc_curve\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "import torch\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "DATASET_PATH = path\n",
        "\n",
        "class_dir = os.path.join(DATASET_PATH)\n",
        "for filename in os.listdir(class_dir):\n",
        "  print(filename)\n",
        "\n",
        "\n",
        "df = pd.read_csv(os.path.join(DATASET_PATH, 'dataset.csv'))\n",
        "df = shuffle(df,random_state=42)\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = df[col].str.replace('_',' ')\n",
        "\n",
        "null_checker = df.apply(lambda x: sum(x.isnull())).to_frame(name='count')\n",
        "\n",
        "cols = df.columns\n",
        "data = df[cols].values.flatten()\n",
        "s = pd.Series(data)\n",
        "s = s.str.strip()\n",
        "s = s.values.reshape(df.shape)\n",
        "\n",
        "df = pd.DataFrame(s, columns=df.columns)\n",
        "\n",
        "df = df.fillna(0)\n",
        "\n",
        "df1 = pd.read_csv(os.path.join(DATASET_PATH, 'Symptom-severity.csv'))\n",
        "x=df1['Symptom']\n",
        "\n",
        "dfx=pd.DataFrame()\n",
        "dfx[\"Disease\"]=df[\"Disease\"]\n",
        "y=0\n",
        "dfx[x]=0\n",
        "for index, row in df.iterrows():\n",
        "    for symptom in df.columns[1:]:\n",
        "        if row[symptom] != 0:\n",
        "            dfx.loc[index, row[symptom]] = 1\n",
        "dfx = dfx.fillna(0)\n",
        "dfx[dfx.columns[1:]]=dfx[dfx.columns[1:]].astype('int')\n",
        "dfx.columns = dfx.columns.str.strip()\n",
        "\n",
        "symptom_sums = dfx.iloc[:, 1:].sum(axis=0)\n",
        "symptoms_with_no_values = symptom_sums[symptom_sums == 0].index.tolist()\n",
        "\n",
        "columns_to_drop = symptoms_with_no_values\n",
        "dfx = dfx.drop(columns=columns_to_drop)\n",
        "dfx[dfx.columns[1:]].sum(axis=0).sort_values()\n",
        "print(dfx.columns.to_list())\n",
        "y=df['Disease'].unique()\n",
        "\n",
        "data = dfx.iloc[:,1:].values\n",
        "labels = dfx['Disease'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI_79KZq9IPx",
        "outputId": "44a24a2b-c5a2-4b64-a550-50de58193842"
      },
      "id": "FI_79KZq9IPx",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/itachi9604/disease-symptom-description-dataset/versions/2\n",
            "Using device: cpu\n",
            "dataset.csv\n",
            "symptom_precaution.csv\n",
            "Symptom-severity.csv\n",
            "symptom_Description.csv\n",
            "['Disease', 'itching', 'shivering', 'chills', 'acidity', 'vomiting', 'fatigue', 'anxiety', 'restlessness', 'lethargy', 'cough', 'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'nausea', 'constipation', 'diarrhoea', 'malaise', 'phlegm', 'congestion', 'dizziness', 'cramps', 'bruising', 'obesity', 'unsteadiness', 'depression', 'irritability', 'polyuria', 'coma', 'palpitations', 'blackheads', 'scurring', 'blister', 'skin rash', 'pus filled pimples', 'mood swings', 'weight loss', 'fast heart rate', 'excessive hunger', 'muscle weakness', 'abnormal menstruation', 'muscle wasting', 'patches in throat', 'high fever', 'extra marital contacts', 'yellowish skin', 'loss of appetite', 'abdominal pain', 'yellowing of eyes', 'chest pain', 'loss of balance', 'lack of concentration', 'blurred and distorted vision', 'drying and tingling lips', 'slurred speech', 'stiff neck', 'swelling joints', 'painful walking', 'dark urine', 'yellow urine', 'receiving blood transfusion', 'receiving unsterile injections', 'visual disturbances', 'burning micturition', 'bladder discomfort', 'foul smell of urine', 'continuous feel of urine', 'irregular sugar level', 'increased appetite', 'joint pain', 'skin peeling', 'small dents in nails', 'inflammatory nails', 'swelling of stomach', 'distention of abdomen', 'history of alcohol consumption', 'fluid overload', 'pain during bowel movements', 'pain in anal region', 'bloody stool', 'irritation in anus', 'acute liver failure', 'stomach bleeding', 'back pain', 'weakness in limbs', 'neck pain', 'mucoid sputum', 'mild fever', 'muscle pain', 'family history', 'continuous sneezing', 'watering from eyes', 'rusty sputum', 'weight gain', 'puffy face and eyes', 'enlarged thyroid', 'brittle nails', 'swollen extremeties', 'swollen legs', 'prominent veins on calf', 'stomach pain', 'spinning movements', 'sunken eyes', 'silver like dusting', 'swelled lymph nodes', 'blood in sputum', 'swollen blood vessels', 'toxic look (typhos)', 'belly pain', 'throat irritation', 'redness of eyes', 'sinus pressure', 'runny nose', 'loss of smell', 'passage of gases', 'cold hands and feets', 'weakness of one body side', 'altered sensorium', 'nodal skin eruptions', 'red sore around nose', 'yellow crust ooze', 'ulcers on tongue', 'spotting  urination', 'pain behind the eyes', 'red spots over body', 'internal itching', 'movement stiffness', 'knee pain', 'hip joint pain', 'dischromic  patches']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_scaled, labels, train_size = 0.8,random_state=42)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "y=le.classes_\n",
        "y\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PeIu8ej9eF7",
        "outputId": "4e75782d-8910-4258-a987-68f925ed3a02"
      },
      "id": "6PeIu8ej9eF7",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3936, 131) (984, 131) (3936,) (984,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0d13ddae",
      "metadata": {
        "id": "0d13ddae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a2abb433-b4e9-4057-8b15-6ddd8172288e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Symptom-severity.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4a04909df249>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msymptom_severity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Symptom-severity.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Symptom-severity.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load Dataset\n",
        "symptom_severity_path = '/content/Symptom-severity.csv'\n",
        "dataset_path = '/content/dataset.csv'\n",
        "\n",
        "# Load the datasets\n",
        "symptom_severity = pd.read_csv(\"/content/Symptom-severity.csv\")\n",
        "dataset = pd.read_csv(dataset_path)\n",
        "\n",
        "# Merge symptom severity into the dataset\n",
        "symptom_mapping = dict(zip(symptom_severity['Symptom'], symptom_severity['weight']))\n",
        "\n",
        "# Replace symptoms with their weights in the dataset\n",
        "symptom_columns = [col for col in dataset.columns if col.startswith('Symptom')]\n",
        "for col in symptom_columns:\n",
        "    dataset[col] = dataset[col].map(symptom_mapping).fillna(0)  # Replace symptoms with weights, fill NaN with 0\n",
        "\n",
        "# Extract features (X) and labels (y)\n",
        "X = dataset[symptom_columns].values  # Symptom severity weights as features\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(dataset['Disease'])  # Encode diseases as numeric labels\n",
        "\n",
        "# Normalize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare PyTorch tensors for training\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "219261df",
      "metadata": {
        "id": "219261df"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the MLP Model\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164e8c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "164e8c65",
        "outputId": "309798df-e874-431f-a477-a2d18d7e32a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 3.7255\n",
            "Epoch [2/10], Loss: 3.7189\n",
            "Epoch [3/10], Loss: 3.7124\n",
            "Epoch [4/10], Loss: 3.7060\n",
            "Epoch [5/10], Loss: 3.6996\n",
            "Epoch [6/10], Loss: 3.6932\n",
            "Epoch [7/10], Loss: 3.6869\n",
            "Epoch [8/10], Loss: 3.6806\n",
            "Epoch [9/10], Loss: 3.6743\n",
            "Epoch [10/10], Loss: 3.6680\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define Model Parameters\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 128\n",
        "num_classes = len(label_encoder.classes_)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "model = MLPModel(input_size, hidden_size, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the Model\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor.to(device))\n",
        "    loss = criterion(outputs, y_train_tensor.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define Model Parameters\n",
        "input_size = x_train.shape[1]\n",
        "hidden_size = 128\n",
        "num_classes = len(le.classes_)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "model = MLPModel(input_size, hidden_size, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the Model with Validation\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor.to(device))\n",
        "    loss = criterion(outputs, y_train_tensor.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == y_train_tensor.to(device)).sum().item()\n",
        "    train_accuracy = correct / y_train_tensor.size(0)\n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test_tensor.to(device))\n",
        "        val_loss = criterion(val_outputs, y_test_tensor.to(device))  # Validation loss\n",
        "        _, val_predicted = torch.max(val_outputs, 1)\n",
        "        val_correct = (val_predicted == y_test_tensor.to(device)).sum().item()\n",
        "        val_accuracy = val_correct / y_test_tensor.size(0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
        "          f\"Training Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy * 100:.2f}%, \"\n",
        "          f\"Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHYnqUiB-vUF",
        "outputId": "d902a1f4-49cf-4918-d2ad-8d600f908c33"
      },
      "id": "jHYnqUiB-vUF",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Training Loss: 3.7418, Training Accuracy: 4.83%, Validation Loss: 3.6447, Validation Accuracy: 8.84%\n",
            "Epoch [2/50], Training Loss: 3.6471, Training Accuracy: 9.22%, Validation Loss: 3.5492, Validation Accuracy: 10.06%\n",
            "Epoch [3/50], Training Loss: 3.5533, Training Accuracy: 11.36%, Validation Loss: 3.4551, Validation Accuracy: 20.43%\n",
            "Epoch [4/50], Training Loss: 3.4608, Training Accuracy: 19.44%, Validation Loss: 3.3617, Validation Accuracy: 30.59%\n",
            "Epoch [5/50], Training Loss: 3.3691, Training Accuracy: 29.09%, Validation Loss: 3.2687, Validation Accuracy: 39.53%\n",
            "Epoch [6/50], Training Loss: 3.2779, Training Accuracy: 39.20%, Validation Loss: 3.1760, Validation Accuracy: 49.80%\n",
            "Epoch [7/50], Training Loss: 3.1871, Training Accuracy: 49.44%, Validation Loss: 3.0832, Validation Accuracy: 58.74%\n",
            "Epoch [8/50], Training Loss: 3.0963, Training Accuracy: 58.49%, Validation Loss: 2.9909, Validation Accuracy: 72.36%\n",
            "Epoch [9/50], Training Loss: 3.0059, Training Accuracy: 70.48%, Validation Loss: 2.8986, Validation Accuracy: 77.03%\n",
            "Epoch [10/50], Training Loss: 2.9155, Training Accuracy: 76.47%, Validation Loss: 2.8061, Validation Accuracy: 84.25%\n",
            "Epoch [11/50], Training Loss: 2.8249, Training Accuracy: 85.34%, Validation Loss: 2.7136, Validation Accuracy: 88.41%\n",
            "Epoch [12/50], Training Loss: 2.7343, Training Accuracy: 88.87%, Validation Loss: 2.6209, Validation Accuracy: 91.77%\n",
            "Epoch [13/50], Training Loss: 2.6434, Training Accuracy: 91.69%, Validation Loss: 2.5281, Validation Accuracy: 93.50%\n",
            "Epoch [14/50], Training Loss: 2.5523, Training Accuracy: 93.09%, Validation Loss: 2.4354, Validation Accuracy: 93.70%\n",
            "Epoch [15/50], Training Loss: 2.4611, Training Accuracy: 93.50%, Validation Loss: 2.3427, Validation Accuracy: 94.41%\n",
            "Epoch [16/50], Training Loss: 2.3699, Training Accuracy: 94.08%, Validation Loss: 2.2503, Validation Accuracy: 96.65%\n",
            "Epoch [17/50], Training Loss: 2.2789, Training Accuracy: 96.42%, Validation Loss: 2.1583, Validation Accuracy: 96.75%\n",
            "Epoch [18/50], Training Loss: 2.1881, Training Accuracy: 96.54%, Validation Loss: 2.0668, Validation Accuracy: 97.26%\n",
            "Epoch [19/50], Training Loss: 2.0977, Training Accuracy: 96.88%, Validation Loss: 1.9759, Validation Accuracy: 97.36%\n",
            "Epoch [20/50], Training Loss: 2.0079, Training Accuracy: 97.15%, Validation Loss: 1.8859, Validation Accuracy: 97.36%\n",
            "Epoch [21/50], Training Loss: 1.9187, Training Accuracy: 97.15%, Validation Loss: 1.7970, Validation Accuracy: 97.36%\n",
            "Epoch [22/50], Training Loss: 1.8305, Training Accuracy: 97.15%, Validation Loss: 1.7093, Validation Accuracy: 97.66%\n",
            "Epoch [23/50], Training Loss: 1.7435, Training Accuracy: 97.38%, Validation Loss: 1.6231, Validation Accuracy: 97.66%\n",
            "Epoch [24/50], Training Loss: 1.6578, Training Accuracy: 97.54%, Validation Loss: 1.5387, Validation Accuracy: 97.66%\n",
            "Epoch [25/50], Training Loss: 1.5738, Training Accuracy: 97.69%, Validation Loss: 1.4561, Validation Accuracy: 99.29%\n",
            "Epoch [26/50], Training Loss: 1.4914, Training Accuracy: 99.11%, Validation Loss: 1.3756, Validation Accuracy: 99.49%\n",
            "Epoch [27/50], Training Loss: 1.4110, Training Accuracy: 99.36%, Validation Loss: 1.2974, Validation Accuracy: 99.59%\n",
            "Epoch [28/50], Training Loss: 1.3328, Training Accuracy: 99.49%, Validation Loss: 1.2218, Validation Accuracy: 99.70%\n",
            "Epoch [29/50], Training Loss: 1.2569, Training Accuracy: 99.62%, Validation Loss: 1.1488, Validation Accuracy: 99.70%\n",
            "Epoch [30/50], Training Loss: 1.1836, Training Accuracy: 99.62%, Validation Loss: 1.0786, Validation Accuracy: 99.80%\n",
            "Epoch [31/50], Training Loss: 1.1129, Training Accuracy: 99.75%, Validation Loss: 1.0112, Validation Accuracy: 99.90%\n",
            "Epoch [32/50], Training Loss: 1.0449, Training Accuracy: 99.87%, Validation Loss: 0.9469, Validation Accuracy: 99.90%\n",
            "Epoch [33/50], Training Loss: 0.9797, Training Accuracy: 99.87%, Validation Loss: 0.8855, Validation Accuracy: 99.90%\n",
            "Epoch [34/50], Training Loss: 0.9175, Training Accuracy: 99.87%, Validation Loss: 0.8272, Validation Accuracy: 99.90%\n",
            "Epoch [35/50], Training Loss: 0.8581, Training Accuracy: 99.87%, Validation Loss: 0.7719, Validation Accuracy: 100.00%\n",
            "Epoch [36/50], Training Loss: 0.8017, Training Accuracy: 100.00%, Validation Loss: 0.7196, Validation Accuracy: 100.00%\n",
            "Epoch [37/50], Training Loss: 0.7483, Training Accuracy: 100.00%, Validation Loss: 0.6703, Validation Accuracy: 100.00%\n",
            "Epoch [38/50], Training Loss: 0.6977, Training Accuracy: 100.00%, Validation Loss: 0.6239, Validation Accuracy: 100.00%\n",
            "Epoch [39/50], Training Loss: 0.6499, Training Accuracy: 100.00%, Validation Loss: 0.5803, Validation Accuracy: 100.00%\n",
            "Epoch [40/50], Training Loss: 0.6049, Training Accuracy: 100.00%, Validation Loss: 0.5394, Validation Accuracy: 100.00%\n",
            "Epoch [41/50], Training Loss: 0.5626, Training Accuracy: 100.00%, Validation Loss: 0.5011, Validation Accuracy: 100.00%\n",
            "Epoch [42/50], Training Loss: 0.5229, Training Accuracy: 100.00%, Validation Loss: 0.4654, Validation Accuracy: 100.00%\n",
            "Epoch [43/50], Training Loss: 0.4858, Training Accuracy: 100.00%, Validation Loss: 0.4320, Validation Accuracy: 100.00%\n",
            "Epoch [44/50], Training Loss: 0.4511, Training Accuracy: 100.00%, Validation Loss: 0.4010, Validation Accuracy: 100.00%\n",
            "Epoch [45/50], Training Loss: 0.4187, Training Accuracy: 100.00%, Validation Loss: 0.3722, Validation Accuracy: 100.00%\n",
            "Epoch [46/50], Training Loss: 0.3885, Training Accuracy: 100.00%, Validation Loss: 0.3454, Validation Accuracy: 100.00%\n",
            "Epoch [47/50], Training Loss: 0.3605, Training Accuracy: 100.00%, Validation Loss: 0.3206, Validation Accuracy: 100.00%\n",
            "Epoch [48/50], Training Loss: 0.3345, Training Accuracy: 100.00%, Validation Loss: 0.2977, Validation Accuracy: 100.00%\n",
            "Epoch [49/50], Training Loss: 0.3104, Training Accuracy: 100.00%, Validation Loss: 0.2765, Validation Accuracy: 100.00%\n",
            "Epoch [50/50], Training Loss: 0.2881, Training Accuracy: 100.00%, Validation Loss: 0.2569, Validation Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_outputs = model(X_test_tensor.to(device))\n",
        "    _, val_predicted = torch.max(val_outputs, 1)\n",
        "    val_correct = (val_predicted == y_test_tensor.to(device)).sum().item()\n",
        "    val_accuracy = val_correct / y_test_tensor.size(0)\n",
        "\n",
        "print(f\"Testing Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "with open('MLPmodel.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "with open('MLPscaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPNhXz7YAF1x",
        "outputId": "a3e0e65f-de65-4ba8-f3e1-8ba8cb412284"
      },
      "id": "KPNhXz7YAF1x",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c76ffb1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c76ffb1d",
        "outputId": "cd299240-c30c-437a-a2a7-c6659cca8402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Disease: Allergy\n",
            "Probabilities: {'(vertigo) Paroymsal  Positional Vertigo': 0.012681626714766026, 'AIDS': 0.009954303503036499, 'Acne': 0.006384456064552069, 'Alcoholic hepatitis': 0.010267342440783978, 'Allergy': 0.5073794722557068, 'Arthritis': 0.010051459074020386, 'Bronchial Asthma': 0.016070546582341194, 'Cervical spondylosis': 0.006008610595017672, 'Chicken pox': 0.00544655229896307, 'Chronic cholestasis': 0.022082846611738205, 'Common Cold': 0.01673133112490177, 'Dengue': 0.010190230794250965, 'Diabetes': 0.005187821574509144, 'Dimorphic hemmorhoids(piles)': 0.01695755310356617, 'Drug Reaction': 0.08069169521331787, 'Fungal infection': 0.021872632205486298, 'GERD': 0.015807896852493286, 'Gastroenteritis': 0.01044006273150444, 'Heart attack': 0.01492294017225504, 'Hepatitis B': 0.00521079869940877, 'Hepatitis C': 0.010144032537937164, 'Hepatitis D': 0.009640875272452831, 'Hepatitis E': 0.006964046973735094, 'Hypertension': 0.006437552627176046, 'Hyperthyroidism': 0.005094541702419519, 'Hypoglycemia': 0.007552138529717922, 'Hypothyroidism': 0.00976971723139286, 'Impetigo': 0.012559656985104084, 'Jaundice': 0.008900986984372139, 'Malaria': 0.018125442788004875, 'Migraine': 0.004884970374405384, 'Osteoarthristis': 0.005577499512583017, 'Paralysis (brain hemorrhage)': 0.007278931327164173, 'Peptic ulcer diseae': 0.017787178978323936, 'Pneumonia': 0.009757012128829956, 'Psoriasis': 0.006078522186726332, 'Tuberculosis': 0.006105130072683096, 'Typhoid': 0.004910130985081196, 'Urinary tract infection': 0.00953433196991682, 'Varicose veins': 0.017556678503751755, 'hepatitis A': 0.011000474914908409}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Prediction Function\n",
        "def predict_disease_mlp(user_input, model, label_encoder, symptom_columns, device, scaler):\n",
        "    # Create a DataFrame with all symptom columns initialized to 0\n",
        "    # user_df = pd.DataFrame(data=[[0] * len(symptom_columns)], columns=symptom_columns)\n",
        "    with open(model, 'rb') as f:\n",
        "      model = pickle.load(f)\n",
        "\n",
        "\n",
        "    # Update values based on user input\n",
        "    # for symptom, value in user_input.items():\n",
        "    #     if symptom in user_df.columns:\n",
        "    #         user_df.loc[0, symptom] = value\n",
        "\n",
        "    # # Scale the input data\n",
        "    # input_scaled = scaler.transform(user_df.values)\n",
        "\n",
        "    # # Convert to PyTorch tensor\n",
        "    # input_tensor = torch.tensor(input_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "    # # Perform prediction\n",
        "    # model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #     output = model(input_tensor)\n",
        "    #     probabilities = torch.softmax(output, dim=1)\n",
        "    #     _, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "    # # Decode prediction\n",
        "    # predicted_label = label_encoder.inverse_transform(predicted.cpu().numpy())\n",
        "    # prob_dict = {label_encoder.inverse_transform([i])[0]: prob.item() for i, prob in enumerate(probabilities[0].cpu())}\n",
        "\n",
        "\n",
        "    user_df = pd.DataFrame([user_input], columns=symptom_columns)\n",
        "    user_df.fillna(0, inplace=True)\n",
        "    input_scaled = scaler.transform(user_df.values)\n",
        "    input_tensor = torch.tensor(input_scaled, dtype=torch.float32).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        _, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "    predicted_label = label_encoder.inverse_transform(predicted.cpu().numpy())\n",
        "    prob_dict = {label_encoder.inverse_transform([i])[0]: prob.item() for i, prob in enumerate(probabilities[0].cpu())}\n",
        "    return predicted_label[0], prob_dict\n",
        "\n",
        "\n",
        "symptom_columns = ['itching', 'shivering', 'chills', 'acidity', 'vomiting', 'fatigue', 'anxiety', 'restlessness', 'lethargy', 'cough', 'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'nausea', 'constipation', 'diarrhoea', 'malaise', 'phlegm', 'congestion', 'dizziness', 'cramps', 'bruising', 'obesity', 'unsteadiness', 'depression', 'irritability', 'polyuria', 'coma', 'palpitations', 'blackheads', 'scurring', 'blister', 'skin rash', 'pus filled pimples', 'mood swings', 'weight loss', 'fast heart rate', 'excessive hunger', 'muscle weakness', 'abnormal menstruation', 'muscle wasting', 'patches in throat', 'high fever', 'extra marital contacts', 'yellowish skin', 'loss of appetite', 'abdominal pain', 'yellowing of eyes', 'chest pain', 'loss of balance', 'lack of concentration', 'blurred and distorted vision', 'drying and tingling lips', 'slurred speech', 'stiff neck', 'swelling joints', 'painful walking', 'dark urine', 'yellow urine', 'receiving blood transfusion', 'receiving unsterile injections', 'visual disturbances', 'burning micturition', 'bladder discomfort', 'foul smell of urine', 'continuous feel of urine', 'irregular sugar level', 'increased appetite', 'joint pain', 'skin peeling', 'small dents in nails', 'inflammatory nails', 'swelling of stomach', 'distention of abdomen', 'history of alcohol consumption', 'fluid overload', 'pain during bowel movements', 'pain in anal region', 'bloody stool', 'irritation in anus', 'acute liver failure', 'stomach bleeding', 'back pain', 'weakness in limbs', 'neck pain', 'mucoid sputum', 'mild fever', 'muscle pain', 'family history', 'continuous sneezing', 'watering from eyes', 'rusty sputum', 'weight gain', 'puffy face and eyes', 'enlarged thyroid', 'brittle nails', 'swollen extremeties', 'swollen legs', 'prominent veins on calf', 'stomach pain', 'spinning movements', 'sunken eyes', 'silver like dusting', 'swelled lymph nodes', 'blood in sputum', 'swollen blood vessels', 'toxic look (typhos)', 'belly pain', 'throat irritation', 'redness of eyes', 'sinus pressure', 'runny nose', 'loss of smell', 'passage of gases', 'cold hands and feets', 'weakness of one body side', 'altered sensorium', 'nodal skin eruptions', 'red sore around nose', 'yellow crust ooze', 'ulcers on tongue', 'spotting  urination', 'pain behind the eyes', 'red spots over body', 'internal itching', 'movement stiffness', 'knee pain', 'hip joint pain', 'dischromic  patches']\n",
        "# Example Input and Prediction\n",
        "user_input = {\n",
        "    'itching': 1,\n",
        "    'skin rash': 1,\n",
        "    'nodal skin eruptions': 0,\n",
        "    'continuous sneezing': 1,\n",
        "    'shivering': 1,\n",
        "    'chills': 1,\n",
        "    'joint pain': 1,\n",
        "    'stomach pain': 1,\n",
        "}\n",
        "\n",
        "predicted_disease, probabilities = predict_disease_mlp(user_input, 'MLPmodel.pkl', le, symptom_columns, device, scaler)\n",
        "print(f\"Predicted Disease: {predicted_disease}\")\n",
        "print(f\"Probabilities: {probabilities}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KNXv2RGUmbQV"
      },
      "id": "KNXv2RGUmbQV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}